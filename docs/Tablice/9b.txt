9b. Komputery i superkomputery


Superkomputery – tym mianem określa się komputery, które w danym okresie
czasu są najszybsze w działaniu. Szybkość superkomputerów mierzy się w FLOPS
(ang. FLoating point Operations Per Second), liczbą operacji zmiennopozycyjnych
na sekundę. Początkowo jednostką była Mflops (MegaFLOPS – 10 6 flops), później
Gflops (GigaFLOPS – 10 9 flops), obecnie Tflops (TeraFLOPS – 10 12 flops), czyli
1 000 000 000 000 operacji na sekundę, a już wkrótce będzie Pflops (PetaFLOPS
– 10 15 flops). Za pierwsze superkomputery uważa się komputery zbudowane przez
Control Data Corporation. Ich konstruktorem był Seymour Cray, powszechnie
uznawany za ojca superkomputerów – były to maszyny CDC 6600 (3 Mflops),
CDC 7600 (36 Mflops) i CDC Star-100 (100 Mflops). W 1972 roku Cray odszedł
z CDC i założył firmę Cray Research, zajmującą się głównie budową superkompu-
terów. Do początków lat 90. komputery Cray zajmowały czołowe miejsca na liście
superkomputerów. Przez ponad dwa lata najszybsza była japońska maszyna Earth
Simulator, a obecnie (rok 2005) prym wiodą komputery budowane przez IBM.
W czerwcu 2005 najszybszy był superkomputer Blue Gene/L (136-183 Tflops), za-
instalowany w Lawrence Livermore National Laboratory w Livermore, będący
wspólnym przedsięwzięciem IBM i National Nuclear Security Administration
Departamentu Energetyki USA.
Pierwsze superkomputery (maszyny CDC) bazowały na szybkich procesorach.
W latach 70. w superkomputerach stosowano procesory wektorowe, a w latach 80.-
90. zaczęto stosować w najszybszych maszynach równoległe systemy procesorów.
Obecnie superkomputery są klasterami mikroprocesorów RISC (ang. Reduced In-
struction Set Computing), takich jak PA-RISC (HP) czy PowerPC (Apple, IBM, Mo-
torola). Na szybkość działania takich maszyn istotny wpływ ma użyta w tych maszy-
nach hierarchiczna budowa pamięci, zapewniająca stały dopływ danych i instrukcji
do procesorów. Wyzwaniem jest również chłodzenie takiej ilości procesorów oraz
minimalizacja długości przewodów (ostatnio zaczęto stosować łączność bezprzewo-
dową).
Systemy operacyjne w superkomputerach bazują na systemie Unix, natomiast
do ich programowania stosuje się specjalne języki, wykorzystujące równoległą ar-
chitekturę jednostki obliczeniowej. Jednymi z najpopularniejszych są odmiany ję-
zyka Fortran, których kompilatory generują znacznie szybsze kody, niż kompilato-
ry języków C czy C++. Testowanie szybkości działania superkomputerów odbywa
się na wybranych przykładach (ang. benchmarks) zagadnień obliczeń algebraicz-
nych Linpack.
Budowane są również superkomputery o specjalnym przeznaczeniu, np. Deep
Blue do gry w szachy (pokonał Gary Kasparowa) czy Deep Crack służący do łama-
nia szyfrów DES. Moc obliczeniową, porównywalną z superkomputerami, mają
rozproszone instalacje komputerów (np. PC). Ocenia się, że na przykład poszuki-
wanie kolejnych dużych liczb pierwszych Mersenne’a w projekcie GIPS ma moc
rzędu 18 Tflops, a system maszyn wyszukujących Google ma moc obliczeniową 100-
300 Tflops.
Superkomputery są stosowane w przypadkach bardzo intensywnych obliczeń
matematycznych, pojawiających się np. przy prognozowaniu pogody i w badaniach
klimatów, modelowaniu molekularnym, symulacji zjawisk fizycznych, kryptoanali-
zie (m. in. przy łamaniu szyfrów). Jednym z najważniejszych ich zastosowań jest sy-
mulacja wybuchów broni jądrowej, co umożliwiło zaprzestanie prowadzenia prób
z tą bronią w przyrodzie.