6a. Logika matematyczna i komputery


George Boole (1815-1864) doprowadził do końca to, co próbował wynaleźć G. W. Leibniz – rachunek logiczny, zwany od jego nazwiska algebrą Boole’a, która umożliwia zapisywanie rozumowania logicznego w postaci rachunku algebraicznego, czyli rachunku na symbolach, które reprezentują zdania i formuły logiczne. Algebra Boole’a ma obecnie szerokie zastosowania w informatyce, np. przy projektowaniu komputerów (układów logicznych) i sieci telekomunikacyjnych oraz w wyszukiwaniu informacji. Rachunek logiczny rozwijał także Augustus de Morgan, który sformalizował operacje logiczne znane obecnie jako transformacje de Morgana. Minęło około 80 lat, aż ten formalizm Boole’a i de Morgana został zauważony i stał się podstawą dalszych badań.
Przełomowe znaczenie dla rozwoju komputerów i budowy sieci telegraficzno-telefonicznych miały prace Claude Elwood Shannona (1916-2001). Położył on podstawy teoretyczne pod praktyczny rozwój dwóch dziedzin techniki, będących motorem rozwoju technologicznego i społecznego w XX wieku: konstrukcji komputerów cyfrowych i teorii komunikacji. Jego osiągnięcia zwiastowały późniejsze zbliżenie się obu tych dziedzin w postaci komunikacji cyfrowej. Po zakończeniu studiów w 1936 roku rozpoczął pracę jako asystent w Massachusetts Institute of Technology, gdzie m.in. uczestniczył przy pracy analizatora różniczkowego (ang. Differential Analyzer), zbudowanego w 1930 roku przez Vannevara Busha. Maszyna ta była wtedy szczytowym osiągnięciem wśród komputerów analogowych – chociaż poruszana motorem elektrycznym, podstawowe operacje były w niej wykonywane mechanicznie, sterowana zaś była układem ponad stu przekaźników. Shannon zainteresował się teorią i projektowaniem takich układów i powiązał je z algebrą Boole’a. W pracy A Symbolic Analysis of Relay and Switching Circuits (1938), opartej na jego pracy magisterskiej, uznawanej powszechnie za najwybitniejszą pracę magisterską XX wieku, wykazał, że algebra Boole’a może być zastosowana w analizie i syntezie układów przełączających i binarnych. Wskazał na analogię między budową obwodów przełączających i algebrą Boole’a – przełącznik w stanie ON lub OFF odpowiada stanowi (zmiennej o wartości) YES lub NO – co umożliwia realizację funkcji logicznej za pomocą sieci przełączników i przekaźników. Dzięki temu algebra Boole’a i arytmetyka binarna mogą być wykorzystane do upraszczania układów przekaźnikowych w centralach telefonicznych, a z drugiej zaś strony układy przekaźników i przełączników mogą być zastosowane do rozwiązywania problemów algebry Boole’a i arytmetyki binarnej. W tamtych czasach oznaczało to przeskok z komputerów analogowych do komputerów cyfrowych i spotkało się z natychmiastowym zainteresowaniem przemysłu telefonicznego.
Claude E. Shannon jest uznawany również za ojca współczesnej teorii informacji. Przed nim wiadomość była utożsamiana z falą, która służyła do jej przesłania liniami, na ogół innymi dla wiadomości telegraficznych, a innymi dla wiadomości głosowych. Shannon zaś przyjął, że każda wiadomość jest ciągiem cyfr binarnych – bitów, jak nazwał cyfrę binarną po raz pierwszy – oddzielił w ten sposób wiadomość od medium, którym jest ona przekazywana. Znaczenie semantyczne informacji nie odgrywa żadnej roli w jego teorii. Ponadto, proces komunikacji z natury ma zasadniczo charakter stochastyczny. W swej pracy A Mathematical Theory of Communication (opublikowanej po raz pierwszy w 1948 roku), od której bierze początek teoria informacji, przyjął fundamentalne założenie, że źródło informacji (np. źródło słów złożonych z pojedynczych symboli) działa jako źródło stacjonarnych procesów stochastycznych. Na tym założeniu oparł definicję miary ilości informacji, metodę pomiaru efektywności kanału komunikacyjnego oraz analizę błędów występujących w przesyłanych wiadomościach. Wprowadził do teorii informacji pojęcie entropii jako miary niepewności, zawartej w przesyłanej wiadomości.
Shannon interesował się również sztuczną inteligencją. Jest autorem jednego z pierwszych programów do gry w szachy (z 1950 roku), wykorzystanego w komputerze MANIAC w 1956 roku, skonstruował elektroniczną mysz szukającą wyjścia z labiryntu i uprościł uniwersalną maszynę Turinga. Wniósł również wkład do kryptografii. Był wielokrotnie nagradzany najwyższymi honorami akademickimi i przemysłowymi. Po ukazaniu się pracy Shannona w 1938 roku wzrosło zainteresowanie zbudowaniem elektronicznej maszyny logicznej. Faktycznie każdy późniejszy komputer cyfrowy był realizacją algebry Boole’a. W rzeczywistości jednak zaprzestano rozwijania specjalnych maszyn logicznych, a skupiono uwagę na komputerach ogólnego przeznaczenia, które dzięki m.in. specjalnym językom programowania okazały się wystarczająco mocne, by rozwiązywać problemy pochodzące z logiki. Jednym z takich języków jest Occam, tak nazwany dla uhonorowania Williama of Ockham (1285-1349), który 500 lat wcześniej odkrył transformacje znane obecnie jako transformacje de Morgana.